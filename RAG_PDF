{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9299042,"sourceType":"datasetVersion","datasetId":5630231},{"sourceId":105881,"sourceType":"modelInstanceVersion","modelInstanceId":88718,"modelId":112929}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-02T10:16:03.070750Z","iopub.execute_input":"2024-09-02T10:16:03.071146Z","iopub.status.idle":"2024-09-02T10:16:03.081523Z","shell.execute_reply.started":"2024-09-02T10:16:03.071108Z","shell.execute_reply":"2024-09-02T10:16:03.080580Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"/kaggle/input/energy/1Ch2.pdf\n/kaggle/input/llama2/pytorch/default/1/llama-2-7b-chat.Q4_K_M.gguf\n","output_type":"stream"}]},{"cell_type":"markdown","source":"I’ve been working in the field of **conversational AI** lately. My latest project has been to create a custom chatbot that can answer questions based on specific PDF documents. I’m using the **Retrieval Augmented Generation (RAG)** to make this happen.","metadata":{}},{"cell_type":"code","source":"!pip install PyPDF2 langchain langchain_community sentence_transformers llama-cpp-python faiss-gpu tiktoken torch","metadata":{"execution":{"iopub.status.busy":"2024-09-02T10:16:13.617753Z","iopub.execute_input":"2024-09-02T10:16:13.618153Z","iopub.status.idle":"2024-09-02T10:16:26.689140Z","shell.execute_reply.started":"2024-09-02T10:16:13.618115Z","shell.execute_reply":"2024-09-02T10:16:26.688140Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: PyPDF2 in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.15)\nRequirement already satisfied: langchain_community in /opt/conda/lib/python3.10/site-packages (0.2.15)\nRequirement already satisfied: sentence_transformers in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: llama-cpp-python in /opt/conda/lib/python3.10/site-packages (0.2.90)\nRequirement already satisfied: faiss-gpu in /opt/conda/lib/python3.10/site-packages (1.7.2)\nRequirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (0.7.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.35 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.37)\nRequirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.108)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.8.2)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.44.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.14.0)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.24.6)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (9.5.0)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (4.12.2)\nRequirement already satisfied: diskcache>=5.6.1 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (5.6.3)\nRequirement already satisfied: jinja2>=2.11.3 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (3.1.4)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2024.5.15)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain) (1.33)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.35->langchain) (2.4)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"#importing the required libraries\nimport PyPDF2\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.llms import LlamaCpp\n\n\nfrom langchain.embeddings import HuggingFaceEmbeddings # import hf embedding\nfrom langchain.vectorstores import FAISS\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.chains import ConversationalRetrievalChain\n\n\nfrom langchain.prompts import PromptTemplate\nfrom sentence_transformers import SentenceTransformer, util\nfrom langchain.callbacks.manager import CallbackManager\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler","metadata":{"execution":{"iopub.status.busy":"2024-09-02T10:16:43.214959Z","iopub.execute_input":"2024-09-02T10:16:43.215781Z","iopub.status.idle":"2024-09-02T10:16:43.222553Z","shell.execute_reply.started":"2024-09-02T10:16:43.215740Z","shell.execute_reply":"2024-09-02T10:16:43.221581Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"pdf_docs=[\"/kaggle/input/energy/1Ch2.pdf\"]","metadata":{"execution":{"iopub.status.busy":"2024-09-02T10:16:44.991713Z","iopub.execute_input":"2024-09-02T10:16:44.992567Z","iopub.status.idle":"2024-09-02T10:16:44.996713Z","shell.execute_reply.started":"2024-09-02T10:16:44.992525Z","shell.execute_reply":"2024-09-02T10:16:44.995653Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def prepare_docs(pdf_docs):\n    docs = []\n    metadata = []\n    content = []\n\n    for pdf in pdf_docs:\n\n        pdf_reader = PyPDF2.PdfReader(pdf)\n        for index, text in enumerate(pdf_reader.pages):\n            doc_page = {'title': pdf + \" page \" + str(index + 1),\n                        'content': pdf_reader.pages[index].extract_text()}\n            docs.append(doc_page)\n    for doc in docs:\n        content.append(doc[\"content\"])\n        metadata.append({\n            \"title\": doc[\"title\"]\n        })\n    print(\"Content and metadata are extracted from the documents\")\n    return content, metadata","metadata":{"execution":{"iopub.status.busy":"2024-09-02T10:16:46.270319Z","iopub.execute_input":"2024-09-02T10:16:46.271201Z","iopub.status.idle":"2024-09-02T10:16:46.278136Z","shell.execute_reply.started":"2024-09-02T10:16:46.271157Z","shell.execute_reply":"2024-09-02T10:16:46.277007Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.cuda.empty_cache()\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-09-02T10:26:06.359563Z","iopub.execute_input":"2024-09-02T10:26:06.359966Z","iopub.status.idle":"2024-09-02T10:26:06.373598Z","shell.execute_reply.started":"2024-09-02T10:26:06.359929Z","shell.execute_reply":"2024-09-02T10:26:06.372727Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"def get_text_chunks(content, metadata):\n    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n        chunk_size=512,\n        chunk_overlap=256,\n    )\n    split_docs = text_splitter.create_documents(content, metadatas=metadata)\n    print(f\"Documents are split into {len(split_docs)} passages\")\n    return split_docs","metadata":{"execution":{"iopub.status.busy":"2024-09-02T10:18:41.272938Z","iopub.execute_input":"2024-09-02T10:18:41.273331Z","iopub.status.idle":"2024-09-02T10:18:41.279703Z","shell.execute_reply.started":"2024-09-02T10:18:41.273292Z","shell.execute_reply":"2024-09-02T10:18:41.278740Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def ingest_into_vectordb(split_docs):\n    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', model_kwargs={'device': device})\n    db = FAISS.from_documents(split_docs, embeddings)\n\n    DB_FAISS_PATH = 'vectorstore/db_faiss'\n    db.save_local(DB_FAISS_PATH)\n    return db","metadata":{"execution":{"iopub.status.busy":"2024-09-02T10:18:58.402585Z","iopub.execute_input":"2024-09-02T10:18:58.403368Z","iopub.status.idle":"2024-09-02T10:18:58.408386Z","shell.execute_reply.started":"2024-09-02T10:18:58.403329Z","shell.execute_reply":"2024-09-02T10:18:58.407336Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"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\")","metadata":{"execution":{"iopub.status.busy":"2024-09-02T10:15:39.693339Z","iopub.status.idle":"2024-09-02T10:15:39.693693Z","shell.execute_reply.started":"2024-09-02T10:15:39.693503Z","shell.execute_reply":"2024-09-02T10:15:39.693520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"template = \"\"\"[INST]\nAs an AI, provide accurate and relevant information based on the provided document. Your responses should adhere to the following guidelines:\n- Answer the question based on the provided documents.\n- Be direct and factual, limited to 50 words and 2-3 sentences. Begin your response without using introductory phrases like yes, no etc.\n- Maintain an ethical and unbiased tone, avoiding harmful or offensive content.\n- If the document does not contain relevant information, state \"I cannot provide an answer based on the provided document.\"\n- Avoid using confirmatory phrases like \"Yes, you are correct\" or any similar validation in your responses.\n- Do not fabricate information or include questions in your responses.\n- do not prompt to select answers. do not ask me questions\n{question}\n[/INST]\n\"\"\"\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\ndef get_conversation_chain(vectordb):\n    llama_llm = LlamaCpp(\n        model_path=\"/kaggle/input/llama2/pytorch/default/1/llama-2-7b-chat.Q4_K_M.gguf\",\n        temperature=0.75,\n        max_tokens=200,\n        top_p=1,\n        callback_manager=callback_manager,\n        n_ctx=3000,\n        device=device  # Ensures LlamaCpp uses the GPU\n    )\n\n    retriever = vectordb.as_retriever()\n    CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(template)\n\n    memory = ConversationBufferMemory(\n        memory_key='chat_history', return_messages=True, output_key='answer')\n\n    conversation_chain = (ConversationalRetrievalChain.from_llm\n                          (llm=llama_llm,\n                           retriever=retriever,\n                           #condense_question_prompt=CONDENSE_QUESTION_PROMPT,\n                           memory=memory,\n                           return_source_documents=True))\n    print(\"Conversational Chain created for the LLM using the vector store\")\n    return conversation_chain","metadata":{"execution":{"iopub.status.busy":"2024-09-02T10:20:25.933198Z","iopub.execute_input":"2024-09-02T10:20:25.933591Z","iopub.status.idle":"2024-09-02T10:20:25.942104Z","shell.execute_reply.started":"2024-09-02T10:20:25.933552Z","shell.execute_reply":"2024-09-02T10:20:25.941143Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def validate_answer_against_sources(response_answer, source_documents):\n    model = SentenceTransformer('all-MiniLM-L6-v2')\n    similarity_threshold = 0.5  \n    source_texts = [doc.page_content for doc in source_documents]\n\n    answer_embedding = model.encode(response_answer, convert_to_tensor=True)\n    source_embeddings = model.encode(source_texts, convert_to_tensor=True)\n\n    cosine_scores = util.pytorch_cos_sim(answer_embedding, source_embeddings)\n\n\n    if any(score.item() > similarity_threshold for score in cosine_scores[0]):\n        return True  \n\n    return False  ","metadata":{"execution":{"iopub.status.busy":"2024-09-02T10:23:27.286527Z","iopub.execute_input":"2024-09-02T10:23:27.287286Z","iopub.status.idle":"2024-09-02T10:23:27.293584Z","shell.execute_reply.started":"2024-09-02T10:23:27.287242Z","shell.execute_reply":"2024-09-02T10:23:27.292580Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"content, metadata = prepare_docs(pdf_docs)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T10:23:29.286053Z","iopub.execute_input":"2024-09-02T10:23:29.286944Z","iopub.status.idle":"2024-09-02T10:23:29.910872Z","shell.execute_reply.started":"2024-09-02T10:23:29.286902Z","shell.execute_reply":"2024-09-02T10:23:29.909889Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Content and metadata are extracted from the documents\n","output_type":"stream"}]},{"cell_type":"code","source":"split_docs = get_text_chunks(content, metadata)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T10:23:29.912549Z","iopub.execute_input":"2024-09-02T10:23:29.912879Z","iopub.status.idle":"2024-09-02T10:23:29.947588Z","shell.execute_reply.started":"2024-09-02T10:23:29.912845Z","shell.execute_reply":"2024-09-02T10:23:29.946503Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Documents are split into 25 passages\n","output_type":"stream"}]},{"cell_type":"code","source":"vectordb=ingest_into_vectordb(split_docs)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T10:23:29.948858Z","iopub.execute_input":"2024-09-02T10:23:29.949176Z","iopub.status.idle":"2024-09-02T10:23:31.127861Z","shell.execute_reply.started":"2024-09-02T10:23:29.949144Z","shell.execute_reply":"2024-09-02T10:23:31.127017Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"conversation_chain=get_conversation_chain(vectordb)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T10:23:42.812535Z","iopub.execute_input":"2024-09-02T10:23:42.812945Z","iopub.status.idle":"2024-09-02T10:23:44.209525Z","shell.execute_reply.started":"2024-09-02T10:23:42.812907Z","shell.execute_reply":"2024-09-02T10:23:44.208651Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/106371208.py:17: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n  llama_llm = LlamaCpp(\nllama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /kaggle/input/llama2/pytorch/default/1/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\nllama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\nllama_model_loader: - kv   0:                       general.architecture str              = llama\nllama_model_loader: - kv   1:                               general.name str              = LLaMA v2\nllama_model_loader: - kv   2:                       llama.context_length u32              = 4096\nllama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\nllama_model_loader: - kv   4:                          llama.block_count u32              = 32\nllama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\nllama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\nllama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\nllama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\nllama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\nllama_model_loader: - kv  10:                          general.file_type u32              = 15\nllama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\nllama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\nllama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\nllama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\nllama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\nllama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\nllama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\nllama_model_loader: - kv  18:               general.quantization_version u32              = 2\nllama_model_loader: - type  f32:   65 tensors\nllama_model_loader: - type q4_K:  193 tensors\nllama_model_loader: - type q6_K:   33 tensors\nllm_load_vocab: special tokens cache size = 3\nllm_load_vocab: token to piece cache size = 0.1684 MB\nllm_load_print_meta: format           = GGUF V2\nllm_load_print_meta: arch             = llama\nllm_load_print_meta: vocab type       = SPM\nllm_load_print_meta: n_vocab          = 32000\nllm_load_print_meta: n_merges         = 0\nllm_load_print_meta: vocab_only       = 0\nllm_load_print_meta: n_ctx_train      = 4096\nllm_load_print_meta: n_embd           = 4096\nllm_load_print_meta: n_layer          = 32\nllm_load_print_meta: n_head           = 32\nllm_load_print_meta: n_head_kv        = 32\nllm_load_print_meta: n_rot            = 128\nllm_load_print_meta: n_swa            = 0\nllm_load_print_meta: n_embd_head_k    = 128\nllm_load_print_meta: n_embd_head_v    = 128\nllm_load_print_meta: n_gqa            = 1\nllm_load_print_meta: n_embd_k_gqa     = 4096\nllm_load_print_meta: n_embd_v_gqa     = 4096\nllm_load_print_meta: f_norm_eps       = 0.0e+00\nllm_load_print_meta: f_norm_rms_eps   = 1.0e-06\nllm_load_print_meta: f_clamp_kqv      = 0.0e+00\nllm_load_print_meta: f_max_alibi_bias = 0.0e+00\nllm_load_print_meta: f_logit_scale    = 0.0e+00\nllm_load_print_meta: n_ff             = 11008\nllm_load_print_meta: n_expert         = 0\nllm_load_print_meta: n_expert_used    = 0\nllm_load_print_meta: causal attn      = 1\nllm_load_print_meta: pooling type     = 0\nllm_load_print_meta: rope type        = 0\nllm_load_print_meta: rope scaling     = linear\nllm_load_print_meta: freq_base_train  = 10000.0\nllm_load_print_meta: freq_scale_train = 1\nllm_load_print_meta: n_ctx_orig_yarn  = 4096\nllm_load_print_meta: rope_finetuned   = unknown\nllm_load_print_meta: ssm_d_conv       = 0\nllm_load_print_meta: ssm_d_inner      = 0\nllm_load_print_meta: ssm_d_state      = 0\nllm_load_print_meta: ssm_dt_rank      = 0\nllm_load_print_meta: ssm_dt_b_c_rms   = 0\nllm_load_print_meta: model type       = 7B\nllm_load_print_meta: model ftype      = Q4_K - Medium\nllm_load_print_meta: model params     = 6.74 B\nllm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \nllm_load_print_meta: general.name     = LLaMA v2\nllm_load_print_meta: BOS token        = 1 '<s>'\nllm_load_print_meta: EOS token        = 2 '</s>'\nllm_load_print_meta: UNK token        = 0 '<unk>'\nllm_load_print_meta: LF token         = 13 '<0x0A>'\nllm_load_print_meta: max token length = 48\nllm_load_tensors: ggml ctx size =    0.14 MiB\nllm_load_tensors:        CPU buffer size =  3891.24 MiB\n..................................................................................................\nllama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\nllama_new_context_with_model: n_ctx      = 3008\nllama_new_context_with_model: n_batch    = 32\nllama_new_context_with_model: n_ubatch   = 32\nllama_new_context_with_model: flash_attn = 0\nllama_new_context_with_model: freq_base  = 10000.0\nllama_new_context_with_model: freq_scale = 1\nllama_kv_cache_init:        CPU KV buffer size =  1504.00 MiB\nllama_new_context_with_model: KV self size  = 1504.00 MiB, K (f16):  752.00 MiB, V (f16):  752.00 MiB\nllama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\nllama_new_context_with_model:        CPU compute buffer size =    14.12 MiB\nllama_new_context_with_model: graph nodes  = 1030\nllama_new_context_with_model: graph splits = 1\n","output_type":"stream"},{"name":"stdout","text":"Conversational Chain created for the LLM using the vector store\n","output_type":"stream"},{"name":"stderr","text":"AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \nModel metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\nUsing fallback chat format: llama-2\n/tmp/ipykernel_36/446300897.py:1: UserWarning: WARNING! device is not default parameter.\n                device was transferred to model_kwargs.\n                Please confirm that device is what you intended.\n  conversation_chain=get_conversation_chain(vectordb)\n","output_type":"stream"}]},{"cell_type":"code","source":"#LETS DO INFERENCE NOW\nuser_question = \"what are the types of energy?\"\nresponse=conversation_chain({\"question\": user_question})\nprint(\"Q: \",user_question)\nprint(\"A: \",response['answer'])","metadata":{"execution":{"iopub.status.busy":"2024-09-02T10:26:14.534860Z","iopub.execute_input":"2024-09-02T10:26:14.535589Z","iopub.status.idle":"2024-09-02T10:32:08.787883Z","shell.execute_reply.started":"2024-09-02T10:26:14.535536Z","shell.execute_reply":"2024-09-02T10:32:08.786998Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"Llama.generate: 624 prefix-match hit, remaining 1474 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":" According to the text, there are several types of energy, including:\n1. Gravitational energy - the energy of place or position, such as water in a reservoir behind a hydroelectric dam;\n2. Kinetic energy - the energy of motion, such as waves, electrons, atoms, and molecules;\n3. Radiant energy - electromagnetic energy that travels in transverse waves, including visible light, x-rays, gamma rays, and radio waves;\n4. Thermal energy - the internal energy within substances due to the vibration and movement of atoms and molecules, such as geothermal energy;\n5. Sound energy - the movement of energy through substances in longitudinal (compression/rarefaction) waves;\n6. Electrical energy - the movement of electrons; and\n7. Chemical energy - the energy stored in the bonds of atoms and molecules","output_type":"stream"},{"name":"stderr","text":"\nllama_print_timings:        load time =    1282.03 ms\nllama_print_timings:      sample time =     102.81 ms /   200 runs   (    0.51 ms per token,  1945.30 tokens per second)\nllama_print_timings: prompt eval time =  308330.71 ms /  1482 tokens (  208.05 ms per token,     4.81 tokens per second)\nllama_print_timings:        eval time =   76585.76 ms /   199 runs   (  384.85 ms per token,     2.60 tokens per second)\nllama_print_timings:       total time =  354215.13 ms /  1681 tokens\n","output_type":"stream"},{"name":"stdout","text":"Q:  what are the types of energy?\nA:   According to the text, there are several types of energy, including:\n1. Gravitational energy - the energy of place or position, such as water in a reservoir behind a hydroelectric dam;\n2. Kinetic energy - the energy of motion, such as waves, electrons, atoms, and molecules;\n3. Radiant energy - electromagnetic energy that travels in transverse waves, including visible light, x-rays, gamma rays, and radio waves;\n4. Thermal energy - the internal energy within substances due to the vibration and movement of atoms and molecules, such as geothermal energy;\n5. Sound energy - the movement of energy through substances in longitudinal (compression/rarefaction) waves;\n6. Electrical energy - the movement of electrons; and\n7. Chemical energy - the energy stored in the bonds of atoms and molecules\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}